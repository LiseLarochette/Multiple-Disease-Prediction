# -*- coding: utf-8 -*-
"""projet_3_coeur.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UXQk-UnW3oT4cXBnePkHUfepfRChqAmB
"""

import pandas as pd

link = "https://raw.githubusercontent.com/MaskiVal/DataSets/main/heartDisease.csv"
df_coeur = pd.read_csv(link)
df_coeur_clean = df_coeur.drop_duplicates()
var_exp = ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach',
       'exang', 'oldpeak', 'slope', 'ca', 'thal']
var_y = ['target']

X = df_coeur_clean[var_exp]
y = df_coeur_clean[var_y]

from sklearn.pipeline import Pipeline
from sklearn.preprocessing import MaxAbsScaler
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, classification_report
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import RandomUnderSampler
from imblearn.pipeline import Pipeline as ImbPipeline
from sklearn.preprocessing import StandardScaler
from sklearn.naive_bayes import GaussianNB
# Diviser les données en ensembles d'entraînement et de test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
# Définir les techniques de rééchantillonnage
over_sampler = SMOTE(random_state=42)
under_sampler = RandomUnderSampler(random_state=42)
# Créer le pipeline avec MaxAbsScaler, SMOTE, RandomUnderSampler, et Logistic Regression
pipeline = ImbPipeline([
    ('scaler', StandardScaler()),
    ('over', over_sampler),
    ('under', under_sampler),
    ('model', GaussianNB())
])
# Entraîner le pipeline
pipeline.fit(X_train, y_train)
# Prédictions sur l'ensemble de test
y_pred = pipeline.predict(X_test)
def prediction_maladie_cardiaque(liste):
  if pipeline.predict(liste)[0] == 0 :
    return "Le risque potentiel de maladie cardiaque est détecté"
  else :
    return "Le risque potentiel de maladie cardiaque n'est pas détecté"
